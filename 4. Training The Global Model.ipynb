{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "459e5f54-bb33-46ee-82cc-d0ceda2ef942",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Loading The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d16e085f-aaf6-47b4-9f3c-96a8f70ed70e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load Utils Module for Current Session"
    }
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "import importlib\n",
    "importlib.reload(utils) # forces the system to load the updated version\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87c43313-3661-41d8-a8e5-98dce8e7997c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load Data and Validate for Potential Leakage"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: /FileStore/tables/paris_project/gold/...\n\n✅ Global Train Count: 1,146,517\n✅ Local Train Count:  40,333\n✅ Test Set Count:      10,935\n✅ No Data Leakage Found (Verified via Broadcast Join)\n"
     ]
    }
   ],
   "source": [
    "ret_data = load_data_and_check_leak(spark, base_path=\"/FileStore/tables/paris_project/gold/\",  test_needed=True,\n",
    "                                    local_path=\"local_train_pool_v5_with_paris_features.parquet\",\n",
    "                                    test_path=\"test_set_v5_with_paris_features.parquet\",\n",
    "                                    global_path=\"global_train_features_v4.parquet\")\n",
    "\n",
    "global_train_df, paris_test_df, local_train_df = ret_data['global_train'], ret_data['test'], ret_data['local_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1907a440-94f7-4cfa-83f9-12a226eaa5a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analysis for: /FileStore/tables/paris_project/gold/global_train_features_v4.parquet ---\nTotal Parquet Files: 76\nTotal Size: 0.06 GB\nAverage File Size: 0.74 MB\nMax File Size: 1.46 MB\n"
     ]
    }
   ],
   "source": [
    "# 1. Analyze YOUR saved data\n",
    "my_data_path = \"/FileStore/tables/paris_project/gold/global_train_features_v4.parquet\"\n",
    "analyze_storage_layout(dbutils, my_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a86545f1-5959-4906-8258-d851220a7c6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dff8748a-3002-4367-83a7-9e4342aa8dd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder, Imputer\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col, when, log1p, expm1\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import split, col, element_at\n",
    "from pyspark.sql.functions import lower\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType, DoubleType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cfa72e8-df50-40f5-a005-4407d195d853",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Required Preprocecing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15b83c0f-0f07-483b-9e18-ce171aeaac86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "MODEL_NAME = \"ֹglobal_pricing_spark_v5\" # CHANGE TO READY MODEL NAME\n",
    "TRAIN_SET = global_train_df #CHANGE TO READY DATASET\n",
    "TARGET_COL = \"log_price\"\n",
    "NUMERIC_COLS =  ['amenities_count_raw','is_supperhost', 'ratings', 'lat','long', 'guests', 'availability_365', 'hosts_year', 'property_number_of_reviews', 'rating_Accuracy', 'rating_Cleanliness', 'rating_Location', 'rating_Value', 'rating_Check-in', 'rating_Communication', 'num_beds', 'num_baths', 'has_dishwasher', 'has_washer']\n",
    "CATEGORICAL_COLS = ['country',  'city', 'region', 'listing_type'] \n",
    "#VECTOR_COLS = ['shared_amenities_vector']\n",
    "#SHARED_AMENITIES_COL = ['Baking sheet', 'Bathtub', 'Coffee maker', 'Dining table', 'Dishwasher', 'First aid kit', 'Hair dryer', 'Hangers', 'Hot water', 'Iron', 'Microwave', 'Oven', 'Refrigerator', 'Shampoo', 'Stove', 'TV', 'Toaster', 'Washer', 'Wifi']\n",
    "\n",
    "#Shared: ['has_bakingsheet', 'has_bathtub', 'has_coffeemaker', 'has_diningtable', 'has_dishwasher', 'has_firstaidkit', 'has_hairdryer', 'has_hangers', 'has_hotwater', 'has_iron', 'has_microwave', 'has_oven', 'has_refrigerator', 'has_shampoo', 'has_stove', 'has_tv', 'has_toaster', 'has_washer', 'has_wifi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0923234e-c35a-48e8-95d8-56de7de539a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: This has placeholders needs to be filled in: [host_number_of_reviews, pos_reviews, is_guest_favorite]\n",
    "\n",
    "def adapt_paris_to_global(local_df):\n",
    "    print(\"\uD83D\uDD27 Adapting Paris Local Set to Global Model Schema...\")\n",
    "\n",
    "    # 2. Complex Mapping & Transformation Pipeline\n",
    "    adapted_df = (local_df\n",
    "        # --- A. Simple Copying (Local -> Global, keep originals) ---\n",
    "        .withColumn(\"lat\", F.col(\"latitude\"))\n",
    "        .withColumn(\"long\", F.col(\"longitude\"))\n",
    "        .withColumn(\"guests\", F.col(\"accommodates\"))\n",
    "        .withColumn(\"num_beds\", F.col(\"beds\"))\n",
    "        .withColumn(\"neighbourhood\", F.col(\"neighbourhood_cleansed\"))\n",
    "        .withColumn(\"property_number_of_reviews\", F.col(\"number_of_reviews\"))\n",
    "        .withColumn(\"num_baths\", F.col(\"bathrooms\"))\n",
    "        # --- B. Ratings Copying (keep originals) ---\n",
    "        .withColumn(\"ratings\", F.col(\"review_scores_rating\"))\n",
    "        .withColumn(\"rating_Accuracy\", F.col(\"review_scores_accuracy\"))\n",
    "        .withColumn(\"rating_Cleanliness\", F.col(\"review_scores_cleanliness\"))\n",
    "        .withColumn(\"rating_Check-in\", F.col(\"review_scores_checkin\"))\n",
    "        .withColumn(\"rating_Communication\", F.col(\"review_scores_communication\"))\n",
    "        .withColumn(\"rating_Location\", F.col(\"review_scores_location\"))\n",
    "        .withColumn(\"rating_Value\", F.col(\"review_scores_value\"))\n",
    "        .withColumn(\"hosts_year\", (F.col(\"host_since\")))\n",
    "        .withColumn(\"is_supperhost\", F.col(\"host_is_superhost\"))\n",
    "        .withColumn(\"amenities_count_raw\", F.col(\"amenities_count\"))        \n",
    "        \n",
    "        # --- E. Location Hardcoding (Critical for Categorical Features) ---\n",
    "        # Since this is the Paris dataset, we hardcode the location info\n",
    "        .withColumn(\"country\", F.lit(\"france\"))\n",
    "        .withColumn(\"city\", F.lit(\"paris\"))\n",
    "        .withColumn(\"region\", F.lit(\"ile-de-france\"))\n",
    "    )\n",
    "        \n",
    "    print(\"✅ Adaptation Mapping Complete.\")\n",
    "    print(f\"Original Local Columns: {len(local_df.columns)}\")\n",
    "    print(f\"Adapted Local Columns:  {len(adapted_df.columns)}\")\n",
    "\n",
    "    # Validation: Check for missing features required by the Global Model\n",
    "    required_global = set(NUMERIC_COLS + CATEGORICAL_COLS)\n",
    "    existing = set(adapted_df.columns)\n",
    "    missing = required_global - existing\n",
    "\n",
    "    if missing:\n",
    "        print(f\"\uD83D\uDEA8 WARNING: Still missing columns for Global Model: {missing}\")\n",
    "    else:\n",
    "        print(\"✨ SUCCESS: All Global Features are present in the Adapted Local Set!\")\n",
    "\n",
    "    return adapted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2afb6fe7-f2ec-46ee-ab8f-0c9e05f6ba56",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1768565719763}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "Data Cleaning and Transformation for Spark DataFrame"
    }
   },
   "outputs": [],
   "source": [
    "def clean_cast_select(df, select=True):\n",
    "    # Casting & Cleaning (Distributed)\n",
    "    for c in NUMERIC_COLS:\n",
    "        if c in df.columns:\n",
    "            df_clean = df.withColumn(c, F.col(c).cast(\"double\"))\n",
    "        else:\n",
    "            print(f\"\uD83D\uDEA8 WARNING: Column {c} not found in the dataset.\")\n",
    "\n",
    "    # Lowercase \n",
    "    for c in CATEGORICAL_COLS:\n",
    "        if c in df.columns:\n",
    "            df_clean = df_clean.withColumn(c, lower(col(c).cast(\"string\")))\n",
    "        else:\n",
    "            print(f\"\uD83D\uDEA8 WARNING: Column {c} not found in the dataset.\")\n",
    "\n",
    "    # Fill nulls in categorical columns\n",
    "    df_clean = df_clean.fillna('other', subset=CATEGORICAL_COLS)\n",
    "\n",
    "\n",
    "    cols_to_use = NUMERIC_COLS + CATEGORICAL_COLS  + [TARGET_COL, 'id']\n",
    "    return df_clean.select(cols_to_use) if select else df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "418d54a9-1e13-42d3-ba97-e91b2a2f8802",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1769634730079}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- 1. Clean Data (Distributed)---\n",
    "df_spark = clean_cast_select(TRAIN_SET)\n",
    "print(\"Train set sample:\")\n",
    "display(df_spark.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e77e8e4b-d495-47ee-97ab-e5c8366c9220",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder, Imputer\n",
    "from pyspark.ml.regression import GBTRegressor, RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col, rand\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87ee97b6-a54c-41c7-9cdd-a86fd431e01e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Preprocess Data"
    }
   },
   "outputs": [],
   "source": [
    "# --- 2. Build Preprocessing Stages (Common for all models) ---\n",
    "numeric_cols = [f.name for f in df_spark.schema.fields if isinstance(f.dataType, (DoubleType, IntegerType)) and f.name not in ['price', 'log_price', 'id']]\n",
    "categorical_cols = [f.name for f in df_spark.schema.fields if isinstance(f.dataType, StringType) and f.name not in ['price', 'log_price', 'id']]\n",
    "vector_cols = [f.name for f in df_spark.schema.fields if isinstance(f.dataType, VectorUDT) and f.name not in ['price', 'log_price', 'id']]\n",
    "\n",
    "stages = []\n",
    "\n",
    "# Imputer\n",
    "imputed_numeric_cols = [f\"imputed_{c}\" for c in numeric_cols]\n",
    "imputer = Imputer(inputCols=numeric_cols, outputCols=imputed_numeric_cols).setStrategy(\"median\")\n",
    "stages.append(imputer)\n",
    "\n",
    "# Categorical\n",
    "encoded_categorical_cols = []\n",
    "for cat_col in categorical_cols:\n",
    "    indexer = StringIndexer(inputCol=cat_col, outputCol=f\"{cat_col}_idx\", handleInvalid=\"keep\")\n",
    "    encoder = OneHotEncoder(inputCols=[f\"{cat_col}_idx\"], outputCols=[f\"{cat_col}_vec\"])\n",
    "    stages.append(indexer)\n",
    "    stages.append(encoder)\n",
    "    encoded_categorical_cols.append(f\"{cat_col}_vec\")\n",
    "\n",
    "# Assembler\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=imputed_numeric_cols + encoded_categorical_cols + vector_cols,\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\"\n",
    ")\n",
    "stages.append(assembler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b450004-283c-4cf2-b3c4-83d17ecf68e2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "first we do a salinity check of scheme matching to test set"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD27 Adapting Paris Local Set to Global Model Schema...\n✅ Adaptation Mapping Complete.\nOriginal Local Columns: 89\nAdapted Local Columns:  109\n✨ SUCCESS: All Global Features are present in the Adapted Local Set!\n"
     ]
    }
   ],
   "source": [
    "test_df_raw = adapt_paris_to_global(paris_test_df)\n",
    "test_df_spark = clean_cast_select(test_df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a840c84-c8ec-44c8-adec-74b644246c46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Model Selection & Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58fc32d3-b9d4-4ae2-a7aa-82e877d23484",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# DEFINE MODEL CANDIDATES\n",
    "# ==============================================================================\n",
    "# Note: Ensure 'features' column exists in your data before this!\n",
    "model_candidates = [\n",
    "    {\n",
    "        \"name\": \"GBT_Deep\",\n",
    "        \"estimator\": GBTRegressor(featuresCol=\"features\", labelCol=\"log_price\", maxIter=50, maxDepth=7, seed=42)\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"GBT_Shallow\",\n",
    "        \"estimator\": GBTRegressor(featuresCol=\"features\", labelCol=\"log_price\", maxIter=20, maxDepth=3, seed=42)\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"GBT_Robust_MAE\", \n",
    "        \"estimator\": GBTRegressor(featuresCol=\"features\", labelCol=\"log_price\", lossType=\"absolute\", maxIter=50, maxDepth=7, seed=42)\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"RandomForest_Baseline\",\n",
    "        \"estimator\": RandomForestRegressor(featuresCol=\"features\", labelCol=\"log_price\", numTrees=50, maxDepth=10, seed=42)\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e3c02b6-da0d-4def-adf8-dc719194ed2c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Model Selection Loop"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import GBTRegressor, RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. PERFORMANCE OPTIMIZATION (CRITICAL FOR SMALL DATA)\n",
    "# ==============================================================================\n",
    "# Since your data is ~50MB, we force it into 4 partitions so all cores work.\n",
    "# If we don't do this, 1 core does everything and the others sleep.\n",
    "train_df, val_df = df_spark.randomSplit([0.8, 0.2], seed=42)\n",
    "print(\"⚡ Optimizing Data Layout...\")\n",
    "train_df = train_df.repartition(4).cache()\n",
    "val_df = val_df.repartition(4).cache()\n",
    "\n",
    "# Trigger an action to materialize the cache immediately\n",
    "print(f\"   -> Training Rows: {train_df.count()}\")\n",
    "print(f\"   -> Validation Rows: {val_df.count()}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. THE TRAINING LOOP\n",
    "# ==============================================================================\n",
    "summary_results = []\n",
    "EXPERIMENT_PATH = \"/Users/ron.bartal@campus.technion.ac.il/Paris_Global_Spark\"\n",
    "\n",
    "mlflow.set_experiment(EXPERIMENT_PATH)\n",
    "print(f\"\\n⚔️ Starting Battle Royale in: {EXPERIMENT_PATH}\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Global_Model_Comparison\") as parent_run:\n",
    "    \n",
    "    for candidate in model_candidates:\n",
    "        model_name = candidate['name']\n",
    "        print(f\"   \uD83C\uDFC3 Training: {model_name}...\")\n",
    "        \n",
    "        with mlflow.start_run(run_name=f\"Trial_{model_name}\", nested=True):\n",
    "            \n",
    "            # A. Build Pipeline\n",
    "            # We take the pre-defined prep stages and add the specific model at the end \n",
    "            # Ensure 'stages' includes your VectorAssembler!\n",
    "            pipeline = Pipeline(stages=stages + [candidate['estimator']])\n",
    "            \n",
    "            # B. Train (Fit)\n",
    "            model = pipeline.fit(train_df)\n",
    "            \n",
    "            # C. Predict (Transform)\n",
    "            preds = model.transform(val_df)\n",
    "            \n",
    "            # D. Evaluate (Distributed Calculation - Fast!)\n",
    "            # 1. R2 Score\n",
    "            evaluator_r2 = RegressionEvaluator(labelCol=\"log_price\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "            r2_score = evaluator_r2.evaluate(preds)\n",
    "            \n",
    "            # 2. Business Metrics (MAE, MAPE, RMSE) calculated via Spark SQL\n",
    "            metrics_df = preds.selectExpr(\n",
    "                \"abs(expm1(log_price) - expm1(prediction)) as error_dollar\",\n",
    "                \"abs((expm1(log_price) - expm1(prediction)) / expm1(log_price)) * 100 as mape_pct\"\n",
    "            )\n",
    "            \n",
    "            stats = metrics_df.selectExpr(\n",
    "                \"mean(error_dollar) as mae\",\n",
    "                \"percentile_approx(error_dollar, 0.5) as med_ae\",\n",
    "                \"mean(mape_pct) as mape\",\n",
    "                \"sqrt(mean(pow(error_dollar, 2))) as rmse\"\n",
    "            ).first()\n",
    "            \n",
    "            # E. Log to MLflow\n",
    "            # Log Parameters\n",
    "            mlflow.log_params(candidate['estimator'].extractParamMap())\n",
    "            \n",
    "            # Log Metrics\n",
    "            mlflow.log_metrics({\n",
    "                \"MAE\": stats['mae'],\n",
    "                \"MedAE\": stats['med_ae'],\n",
    "                \"MAPE\": stats['mape'],\n",
    "                \"RMSE\": stats['rmse'],\n",
    "                \"R2_log\": r2_score\n",
    "            })\n",
    "            \n",
    "            # Save to local summary list\n",
    "            summary_results.append({\n",
    "                \"Model\": model_name,\n",
    "                \"MAE ($)\": stats['mae'],\n",
    "                \"MedAE ($)\": stats['med_ae'],\n",
    "                \"MAPE (%)\": stats['mape'],\n",
    "                \"RMSE ($)\": stats['rmse'],\n",
    "                \"R2 (log)\": r2_score\n",
    "            })\n",
    "            \n",
    "            print(f\"      ✅ Done. MAE: ${stats['mae']:.2f} | R2: {r2_score:.3f}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. FINAL LEADERBOARD\n",
    "# ==============================================================================\n",
    "leaderboard = pd.DataFrame(summary_results).sort_values(by=\"MAE ($)\")\n",
    "print(\"\\n\uD83C\uDFC6 FINAL RESULTS LEADERBOARD:\")\n",
    "display(leaderboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d53a020-a09a-4d08-a098-2b91bb5371b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Train Full Model & valuate On Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e970480c-0df0-4bc7-8b34-f1ff0c9f230c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Train Final Model"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD27 Adapting Paris Local Set to Global Model Schema...\n✅ Adaptation Mapping Complete.\nOriginal Local Columns: 89\nAdapted Local Columns:  109\n✨ SUCCESS: All Global Features are present in the Adapted Local Set!\n\uD83D\uDE80 Training Final Production Model: ֹglobal_pricing_spark_v5 (GBT_Deep)...\n✅ Training on 1146517 rows...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/29 11:05:18 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fce6a0357e240819f5e4f06af2c6076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/29 11:06:18 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: dbfs:/databricks/mlflow-tracking/3630736412863185/d3485b339bda4ed28c1cce615457154b/artifacts/model/sparkml, flavor: spark). Fall back to return ['pyspark==3.5.0']. Set logging level to DEBUG to see the full traceback. \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d5083001cb458482da2814830d0c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'ֹglobal_pricing_spark_v5 (GBT_Deep)' already exists. Creating a new version of this model...\n2026/01/29 11:06:20 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ֹglobal_pricing_spark_v5 (GBT_Deep), version 5\nCreated version '5' of model 'ֹglobal_pricing_spark_v5 (GBT_Deep)'.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83C\uDFC3 View run Final_Model_For_Eval at: https://adb-983293358114278.18.azuredatabricks.net/ml/experiments/3630736412863185/runs/d3485b339bda4ed28c1cce615457154b\n\uD83E\uDDEA View experiment at: https://adb-983293358114278.18.azuredatabricks.net/ml/experiments/3630736412863185\n"
     ]
    }
   ],
   "source": [
    "# --- USER INPUT REQUIRED ---\n",
    "CHOSEN_ARCHITECTURE = \"GBT_Deep\" # <--- #TODO: Update this based on the leaderboard above!\n",
    "chosen_model_name = f\"{MODEL_NAME} ({CHOSEN_ARCHITECTURE})\"\n",
    "# ---------------------------\n",
    "\n",
    "print(f\"\uD83D\uDE80 Training Final Production Model: {chosen_model_name}...\")\n",
    "\n",
    "# 1. Find the estimator config\n",
    "selected_candidate = next(c for c in model_candidates if c['name'] == CHOSEN_ARCHITECTURE)\n",
    "\n",
    "# 2. Retrain on FULL Data\n",
    "final_pipeline = Pipeline(stages=stages + [selected_candidate['estimator']])\n",
    "full_data = df_spark.repartition(4).cache()\n",
    "print(f\"✅ Training on {full_data.count()} rows...\")\n",
    "with mlflow.start_run(run_name=\"Final_Model_For_Eval\"):\n",
    "    final_model = final_pipeline.fit(full_data)\n",
    "    #preds_test = final_model.transform(test_df_spark)\n",
    "    \n",
    "    # 3. Log Model\n",
    "    mlflow.spark.log_model(final_model, \"model\", registered_model_name=chosen_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30c8cfbb-c529-4621-86cc-d1ba03125bfc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Evaluate on Test Set"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mException\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-5658576270839943>, line 17\u001B[0m\n",
       "\u001B[1;32m     15\u001B[0m full_data \u001B[38;5;241m=\u001B[39m df_spark\u001B[38;5;241m.\u001B[39mrepartition(\u001B[38;5;241m4\u001B[39m)\u001B[38;5;241m.\u001B[39mcache()\n",
       "\u001B[1;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m✅ Training on \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfull_data\u001B[38;5;241m.\u001B[39mcount()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m rows...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[0;32m---> 17\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m mlflow\u001B[38;5;241m.\u001B[39mstart_run(run_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFinal_Model_For_Eval\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\u001B[1;32m     18\u001B[0m     final_model \u001B[38;5;241m=\u001B[39m final_pipeline\u001B[38;5;241m.\u001B[39mfit(full_data)\n",
       "\u001B[1;32m     19\u001B[0m     \u001B[38;5;66;03m#preds_test = final_model.transform(test_df_spark)\u001B[39;00m\n",
       "\u001B[1;32m     20\u001B[0m     \n",
       "\u001B[1;32m     21\u001B[0m     \u001B[38;5;66;03m# 3. Log Model\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/mlflow/tracking/fluent.py:351\u001B[0m, in \u001B[0;36mstart_run\u001B[0;34m(run_id, experiment_id, run_name, nested, parent_run_id, tags, description, log_system_metrics)\u001B[0m\n",
       "\u001B[1;32m    349\u001B[0m experiment_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(experiment_id) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(experiment_id, \u001B[38;5;28mint\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m experiment_id\n",
       "\u001B[1;32m    350\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(active_run_stack) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m nested:\n",
       "\u001B[0;32m--> 351\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\n",
       "\u001B[1;32m    352\u001B[0m         (\n",
       "\u001B[1;32m    353\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRun with UUID \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m is already active. To start a new run, first end the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    354\u001B[0m             \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcurrent run with mlflow.end_run(). To start a nested \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    355\u001B[0m             \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun, call start_run with nested=True\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    356\u001B[0m         )\u001B[38;5;241m.\u001B[39mformat(active_run_stack[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mrun_id)\n",
       "\u001B[1;32m    357\u001B[0m     )\n",
       "\u001B[1;32m    358\u001B[0m client \u001B[38;5;241m=\u001B[39m MlflowClient()\n",
       "\u001B[1;32m    359\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m run_id:\n",
       "\n",
       "\u001B[0;31mException\u001B[0m: Run with UUID df9ac63d547840e08564cc7cdddb02ca is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "Exception",
        "evalue": "Run with UUID df9ac63d547840e08564cc7cdddb02ca is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True"
       },
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mException\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-5658576270839943>, line 17\u001B[0m\n\u001B[1;32m     15\u001B[0m full_data \u001B[38;5;241m=\u001B[39m df_spark\u001B[38;5;241m.\u001B[39mrepartition(\u001B[38;5;241m4\u001B[39m)\u001B[38;5;241m.\u001B[39mcache()\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m✅ Training on \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfull_data\u001B[38;5;241m.\u001B[39mcount()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m rows...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 17\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m mlflow\u001B[38;5;241m.\u001B[39mstart_run(run_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFinal_Model_For_Eval\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     18\u001B[0m     final_model \u001B[38;5;241m=\u001B[39m final_pipeline\u001B[38;5;241m.\u001B[39mfit(full_data)\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;66;03m#preds_test = final_model.transform(test_df_spark)\u001B[39;00m\n\u001B[1;32m     20\u001B[0m     \n\u001B[1;32m     21\u001B[0m     \u001B[38;5;66;03m# 3. Log Model\u001B[39;00m\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/mlflow/tracking/fluent.py:351\u001B[0m, in \u001B[0;36mstart_run\u001B[0;34m(run_id, experiment_id, run_name, nested, parent_run_id, tags, description, log_system_metrics)\u001B[0m\n\u001B[1;32m    349\u001B[0m experiment_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(experiment_id) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(experiment_id, \u001B[38;5;28mint\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m experiment_id\n\u001B[1;32m    350\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(active_run_stack) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m nested:\n\u001B[0;32m--> 351\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\n\u001B[1;32m    352\u001B[0m         (\n\u001B[1;32m    353\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRun with UUID \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m is already active. To start a new run, first end the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    354\u001B[0m             \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcurrent run with mlflow.end_run(). To start a nested \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    355\u001B[0m             \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun, call start_run with nested=True\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    356\u001B[0m         )\u001B[38;5;241m.\u001B[39mformat(active_run_stack[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mrun_id)\n\u001B[1;32m    357\u001B[0m     )\n\u001B[1;32m    358\u001B[0m client \u001B[38;5;241m=\u001B[39m MlflowClient()\n\u001B[1;32m    359\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m run_id:\n",
        "\u001B[0;31mException\u001B[0m: Run with UUID df9ac63d547840e08564cc7cdddb02ca is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "raise Exception(\"TODO: Paste your Run ID below (Found in MLflow UI -> Experiment -> Run -> Artifacts) or exeption will raise\")\n",
    "RUN_ID = \"\"\n",
    "MODEL_URI = f\"runs:/{RUN_ID}/model\"\n",
    "\n",
    "# =========================================\n",
    "# 2. Preprocess test data\n",
    "# =========================================\n",
    "print(\"\uD83D\uDD27 Preprocessing test data...\")\n",
    "adapted_test_df = adapt_paris_to_global(paris_test_df)\n",
    "test_clean = clean_cast_select(adapted_test_df)\n",
    "\n",
    "# ==========================================\n",
    "# 3. LOAD MODEL FROM STORAGE\n",
    "# ==========================================\n",
    "print(f\"\uD83D\uDCE5 Loading model from MLflow: {MODEL_URI}...\")\n",
    "final_model = mlflow.spark.load_model(MODEL_URI)\n",
    "final_model_name = type(final_model.stages[-1]).__name__\n",
    "print(f\"✅ Model loaded successfully into memory: {final_model_name}\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. PREDICT & EVALUATE\n",
    "# ==========================================\n",
    "print(\"\uD83D\uDE80 Running Inference on Test Set...\")\n",
    "preds_test = final_model.transform(test_clean)\n",
    "\n",
    "# Calculate Metrics\n",
    "metrics_df = preds_test.selectExpr(\n",
    "    \"abs(expm1(log_price) - expm1(prediction)) as error_dollar\",\n",
    "    \"abs((expm1(log_price) - expm1(prediction)) / expm1(log_price)) * 100 as mape_pct\"\n",
    ")\n",
    "\n",
    "stats = metrics_df.selectExpr(\n",
    "    \"mean(error_dollar) as mae\",\n",
    "    \"percentile_approx(error_dollar, 0.5) as med_ae\",\n",
    "    \"mean(mape_pct) as mape\",\n",
    "    \"sqrt(mean(pow(error_dollar, 2))) as rmse\"\n",
    ").first()\n",
    "\n",
    "# R2 Score\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"log_price\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2_score = evaluator_r2.evaluate(preds_test)\n",
    "\n",
    "print(\"\\n\uD83C\uDFC6 RESULTS FROM LOADED MODEL:\")\n",
    "print(f\"   R2 (Log): {r2_score:.4f}\")\n",
    "print(f\"   MAE:      ${stats['mae']:.2f}\")\n",
    "print(f\"   MedAE:    ${stats['med_ae']:.2f} (Median Error)\")\n",
    "print(f\"   MAPE:     {stats['mape']:.2f}%\")\n",
    "print(f\"   RMSE:     ${stats['rmse']:.2f}\")\n",
    "\n",
    "# Optional: Generate plots again if needed\n",
    "# log_visualizations(preds_test, title_prefix=\"Reloaded_Model_Check\")\n",
    " # 4. Generate Standard Plots (Actual vs Pred)\n",
    "log_visualizations(preds_test, final_model=final_model, chosen_model_name=final_model_name,title_prefix=\"Final_Production\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56a8e806-9ebb-4b67-9df5-687c589055b3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Save Global Predictions for the Experiment Run"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mException\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-5658576270839943>, line 17\u001B[0m\n",
       "\u001B[1;32m     15\u001B[0m full_data \u001B[38;5;241m=\u001B[39m df_spark\u001B[38;5;241m.\u001B[39mrepartition(\u001B[38;5;241m4\u001B[39m)\u001B[38;5;241m.\u001B[39mcache()\n",
       "\u001B[1;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m✅ Training on \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfull_data\u001B[38;5;241m.\u001B[39mcount()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m rows...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[0;32m---> 17\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m mlflow\u001B[38;5;241m.\u001B[39mstart_run(run_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFinal_Model_For_Eval\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\u001B[1;32m     18\u001B[0m     final_model \u001B[38;5;241m=\u001B[39m final_pipeline\u001B[38;5;241m.\u001B[39mfit(full_data)\n",
       "\u001B[1;32m     19\u001B[0m     \u001B[38;5;66;03m#preds_test = final_model.transform(test_df_spark)\u001B[39;00m\n",
       "\u001B[1;32m     20\u001B[0m     \n",
       "\u001B[1;32m     21\u001B[0m     \u001B[38;5;66;03m# 3. Log Model\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/mlflow/tracking/fluent.py:351\u001B[0m, in \u001B[0;36mstart_run\u001B[0;34m(run_id, experiment_id, run_name, nested, parent_run_id, tags, description, log_system_metrics)\u001B[0m\n",
       "\u001B[1;32m    349\u001B[0m experiment_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(experiment_id) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(experiment_id, \u001B[38;5;28mint\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m experiment_id\n",
       "\u001B[1;32m    350\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(active_run_stack) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m nested:\n",
       "\u001B[0;32m--> 351\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\n",
       "\u001B[1;32m    352\u001B[0m         (\n",
       "\u001B[1;32m    353\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRun with UUID \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m is already active. To start a new run, first end the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    354\u001B[0m             \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcurrent run with mlflow.end_run(). To start a nested \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    355\u001B[0m             \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun, call start_run with nested=True\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    356\u001B[0m         )\u001B[38;5;241m.\u001B[39mformat(active_run_stack[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mrun_id)\n",
       "\u001B[1;32m    357\u001B[0m     )\n",
       "\u001B[1;32m    358\u001B[0m client \u001B[38;5;241m=\u001B[39m MlflowClient()\n",
       "\u001B[1;32m    359\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m run_id:\n",
       "\n",
       "\u001B[0;31mException\u001B[0m: Run with UUID df9ac63d547840e08564cc7cdddb02ca is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "Exception",
        "evalue": "Run with UUID df9ac63d547840e08564cc7cdddb02ca is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True"
       },
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mException\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-5658576270839943>, line 17\u001B[0m\n\u001B[1;32m     15\u001B[0m full_data \u001B[38;5;241m=\u001B[39m df_spark\u001B[38;5;241m.\u001B[39mrepartition(\u001B[38;5;241m4\u001B[39m)\u001B[38;5;241m.\u001B[39mcache()\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m✅ Training on \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfull_data\u001B[38;5;241m.\u001B[39mcount()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m rows...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 17\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m mlflow\u001B[38;5;241m.\u001B[39mstart_run(run_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFinal_Model_For_Eval\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     18\u001B[0m     final_model \u001B[38;5;241m=\u001B[39m final_pipeline\u001B[38;5;241m.\u001B[39mfit(full_data)\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;66;03m#preds_test = final_model.transform(test_df_spark)\u001B[39;00m\n\u001B[1;32m     20\u001B[0m     \n\u001B[1;32m     21\u001B[0m     \u001B[38;5;66;03m# 3. Log Model\u001B[39;00m\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/mlflow/tracking/fluent.py:351\u001B[0m, in \u001B[0;36mstart_run\u001B[0;34m(run_id, experiment_id, run_name, nested, parent_run_id, tags, description, log_system_metrics)\u001B[0m\n\u001B[1;32m    349\u001B[0m experiment_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(experiment_id) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(experiment_id, \u001B[38;5;28mint\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m experiment_id\n\u001B[1;32m    350\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(active_run_stack) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m nested:\n\u001B[0;32m--> 351\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\n\u001B[1;32m    352\u001B[0m         (\n\u001B[1;32m    353\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRun with UUID \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m is already active. To start a new run, first end the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    354\u001B[0m             \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcurrent run with mlflow.end_run(). To start a nested \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    355\u001B[0m             \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun, call start_run with nested=True\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    356\u001B[0m         )\u001B[38;5;241m.\u001B[39mformat(active_run_stack[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mrun_id)\n\u001B[1;32m    357\u001B[0m     )\n\u001B[1;32m    358\u001B[0m client \u001B[38;5;241m=\u001B[39m MlflowClient()\n\u001B[1;32m    359\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m run_id:\n",
        "\u001B[0;31mException\u001B[0m: Run with UUID df9ac63d547840e08564cc7cdddb02ca is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "raise Exception(\"TODO: Paste your Run ID below (Found in MLflow UI -> Experiment -> Run -> Artifacts)\")\n",
    "RUN_ID = \"\"\n",
    "MODEL_URI = f\"runs:/{RUN_ID}/model\"\n",
    "OUTPUT_LOCAL_TRAIN_WITH_GLOBAL_PRED = \"/FileStore/tables/paris_project/diamond/local_train_with_global_pred_v7.parquet\"\n",
    "OUTPUT_TEST_WITH_PRED = \"/FileStore/tables/paris_project/diamond/test_set_with_global_pred_v7.parquet\"\n",
    "local_train_raw = local_train_df\n",
    "test_raw = paris_test_df\n",
    "\n",
    "# ==========================================\n",
    "# 2. LOAD MODEL FROM STORAGE\n",
    "# ==========================================\n",
    "print(f\"\uD83D\uDCE5 Loading model from MLflow: {MODEL_URI}...\")\n",
    "final_model = mlflow.spark.load_model(MODEL_URI)\n",
    "print(\"✅ Model loaded successfully into memory.\")\n",
    "\n",
    "# =========================================\n",
    "# 3. Preprocess test data\n",
    "# =========================================\n",
    "print(\"\uD83D\uDD27 Preprocessing train data...\")\n",
    "final_cols = local_train_raw.columns + [\"global_pred_log\"]\n",
    "print(final_cols)\n",
    "adapted_local_train = adapt_paris_to_global(local_train_raw)\n",
    "local_train_clean = clean_cast_select(adapted_local_train, select=False)\n",
    "\n",
    "# Predict using the loaded/trained Global Model\n",
    "\n",
    "# Transform\n",
    "train_preds = final_model.transform(local_train_clean)\n",
    "\n",
    "# Just drop the heavy vector column ('features') and save everything else.\n",
    "(train_preds\n",
    " .withColumnRenamed(\"prediction\", \"global_pred_log\")\n",
    " .select(final_cols)\n",
    " .write.mode(\"overwrite\").parquet(OUTPUT_LOCAL_TRAIN_WITH_GLOBAL_PRED)\n",
    ")\n",
    "print(f\"✅ Saved Local Train with Global Preds to: {OUTPUT_LOCAL_TRAIN_WITH_GLOBAL_PRED}\")\n",
    "\n",
    "\n",
    "# --- 3. Process & Save Test Set ---\n",
    "print(\"\uD83D\uDD27 Preprocessing test data...\")\n",
    "adapted_test = adapt_paris_to_global(test_raw)\n",
    "test_clean = clean_cast_select(adapted_test, select=False)\n",
    "\n",
    "print(\"\uD83D\uDE80 Processing Test Set...\")\n",
    "test_preds = final_model.transform(test_clean)\n",
    "\n",
    "(test_preds\n",
    " .withColumnRenamed(\"prediction\", \"global_pred_log\")\n",
    " .select(final_cols)\n",
    " .write.mode(\"overwrite\").parquet(OUTPUT_TEST_WITH_PRED)\n",
    ")\n",
    "print(f\"✅ Saved Test Set with Global Preds to: {OUTPUT_TEST_WITH_PRED}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4. Training The Global Model",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}